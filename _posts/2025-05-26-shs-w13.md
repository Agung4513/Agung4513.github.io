---
title: "Second Half Semester Summary - Week 13 Materials: Huffman Coding, N-Queens Problem, and Subset Sum"
date: 2025-05-26 00:00:00 +0800
categories: [Second Half Semester]
---

# Week 13 Summary - Second Half Semester
In the 13th week of the second semester, three main topics were discussed: **Huffman Coding**, **N-Queens Problem**, and **Subset Sum**.

---

## Huffman Coding

Huffman Coding is a lossless data compression technique developed by David A. Huffman in 1952. This method is widely used in data processing due to its ability to reduce data size without losing any information. Huffman Coding works by replacing frequently occurring symbols in data with shorter bit codes, while assigning longer codes to less frequent symbols. This approach is particularly effective in various popular compression formats such as ZIP, JPEG, and MP3.

The core idea of Huffman Coding revolves around the frequency of character occurrences in a dataset. Characters that appear more frequently are assigned shorter binary codes to save storage space, while rarely occurring characters are given longer codes. To represent this relationship efficiently, a binary tree structure is used, where each node represents a character and its frequency.

The process begins by calculating the frequency of each character in the data. A node is then created for each character based on its frequency. The two nodes with the smallest frequencies are merged into a new node. This process continues until a complete Huffman Tree is formed. Once the tree is built, each character is assigned a binary code based on a simple rule: left branches represent 0, and right branches represent 1.

The main advantage of Huffman Coding is its lossless nature, ensuring that no information is lost during compression. It is also highly efficient for datasets with non-uniform character distributions and is widely applied in file compression systems. However, it has some drawbacks, such as being less optimal when character frequencies are uniform and requiring a code table for decompression.

## N-Queens Problem

The N-Queens Problem is a classic problem in computer science and combinatorial mathematics. It involves placing N chess queens on an N × N chessboard in such a way that no two queens attack each other. In chess, queens can move horizontally, vertically, and diagonally, so the challenge is to position them so that none share the same row, column, or diagonal. One of the most well-known versions is the 8-Queens Problem, where eight queens must be placed on an 8x8 board under the same constraints.

The objective of the N-Queens Problem is not only to find one valid solution but to identify all possible valid configurations. This problem is widely used to develop and test various search and optimization algorithms such as backtracking, depth-first search (DFS), heuristic search, and even genetic algorithms. It is also a crucial exercise for enhancing logic programming and problem-solving skills, particularly in the context of Constraint Satisfaction Problems (CSP).

The relevance of the N-Queens Problem extends beyond theory. In academia, it serves as a case study to understand search techniques like backtracking and heuristics. It also introduces the concept of CSP, where variables must be assigned values under specific constraints. Furthermore, the principles behind the N-Queens Problem have real-world applications, such as task scheduling, circuit module placement, and exclusive resource allocation. The problem also illustrates how complexity grows exponentially with larger N, making it an effective benchmark for testing algorithm efficiency.

The N-Queens Problem is ideally solved using backtracking. In this approach, queens are placed one by one starting from the first row. Each step attempts to place a queen in a different column and checks if the position is safe from previously placed queens. If no safe position is found, the algorithm backtracks to the previous step and tries a different option—this is known as backtracking. Each queen placement can be seen as a node in the solution search tree. If a path does not lead to a valid solution, it is pruned, and the search continues along another branch.

In an educational context, the N-Queens Problem is highly relevant. As a case study for backtracking, it helps students understand how to construct solutions incrementally and avoid unnecessary exploration. From an algorithm analysis perspective, it provides insight into the efficiency differences between brute-force and backtracking approaches. It also introduces students to CSP models and advanced techniques such as forward checking and backjumping.

## Subset Sum Problem

The Subset Sum Problem (SSP) is a classic problem in computer science that falls under the NP-Complete category. It deals with a set of integers and a specific target value. The goal is to determine whether there exists a subset of these integers whose elements sum up to the given target.

Subset Sum is considered a decision problem, meaning it requires a yes or no answer—does such a subset exist or not? This problem is computationally complex because no known algorithm can solve all cases in polynomial time. However, several approaches have been developed to address the Subset Sum Problem, such as brute-force, backtracking, dynamic programming, and optimization-based methods.

This problem holds importance not only in theoretical computing but also in practical applications, such as cryptography, financial planning, and decision-making systems. Due to its complexity and challenge, the Subset Sum Problem is often used as a teaching example in advanced algorithm and data structure courses.
